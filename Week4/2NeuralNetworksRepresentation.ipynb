{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Representation\n",
    "\n",
    "Neural Networks were developed as simulating networks of neurons in the brain. So, to start understanding the representation of these hypotheses, let's start by understanding how a single neuron in the brain works: \n",
    "\n",
    "![Biological neuron](https://upload.wikimedia.org/wikipedia/commons/4/44/Neuron3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components of the neuron are:\n",
    "\n",
    "- A cell body;\n",
    "- Input wires (dendrites);\n",
    "- Output wire (axon).\n",
    "\n",
    "The axon often goes to the dendrites of other neurons, forming a network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurons communicate via pulses of electricity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron model: Logistic unit\n",
    "\n",
    "Given the above, we're going to use a very simple model of the neuron:\n",
    "\n",
    "![single neuron](figures/single_neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where \n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = \\frac{1}{1 + e^{-\\theta^T x}} = g(\\theta^T x)\n",
    "$$\n",
    "\n",
    "with $x=[x_0 \\quad x_1 \\quad x_2 \\quad x_3]^T$ and $\\theta=[\\theta_0 \\quad \\theta_1 \\quad \\theta_2 \\quad \\theta_3]^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are using the sigmoid (logistic) function as the **activation function**. Other functions such as $\\tanh(\\cdot)$ or $\\mathrm{ReLU(\\cdot)}=\\max\\{0, \\cdot\\}$ are also used often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network\n",
    "\n",
    "A neural networks is a group of these neurons acting together:\n",
    "\n",
    "![neural network](figures/neural_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this network:\n",
    "\n",
    "- $a_i^{(j)}$ is the activation of unit $i$ in layer $j$.\n",
    "- $\\Theta^{(j)}$ is the matrix of weights controlling function mapping from layer $j$ to layer $j+1$.\n",
    "\n",
    "Thus:\n",
    "\n",
    "\\begin{align}\n",
    "a_1^{(2)} &= g(\\Theta_{10}^{(1)} x_0 + \\Theta_{11}^{(1)} x_1 + \\Theta_{12}^{(1)} x_2 + \\Theta_{13}^{(1)} x_3) \\\\\n",
    "a_2^{(2)} &= g(\\Theta_{20}^{(1)} x_0 + \\Theta_{21}^{(1)} x_1 + \\Theta_{22}^{(1)} x_2 + \\Theta_{23}^{(1)} x_3) \\\\\n",
    "a_3^{(2)} &= g(\\Theta_{30}^{(1)} x_0 + \\Theta_{31}^{(1)} x_1 + \\Theta_{32}^{(1)} x_2 + \\Theta_{33}^{(1)} x_3) \\\\\n",
    "& \\\\\n",
    "h_{\\Theta}(x) &= a_1^{(3)} = g(\\Theta_{10}^{(3)} a_0^{(2)} + \\Theta_{11}^{(2)} a_1^{(2)} + \\Theta_{32}^{(2)} a_2^{(2)} + \\Theta_{33}^{(2)} a_3^{(2)})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setting $\\Theta^{(1)} \\in \\mathbb{R}^{3 \\times 4}$ and $\\Theta^{(2)} \\in \\mathbb{R}^{1 \\times 4}$.\n",
    "\n",
    "In general, if a network has $s_j$ units in layer $j$, and $s_{j+1}$ units in layer $j+1$, then $\\Theta^{(j)}$ will be of dimension $s_{j+1} \\times (1 + s_j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above setting, we can define intermediate variables \n",
    "\n",
    "$$\n",
    "z^{(j+1)}_i = \\Theta_{i0}^{(j)} a_0^{(j)} + \\Theta_{i1}^{(j)} a_1^{(j)} + \\Theta_{i2}^{(j)} a_2^{(j)} + \\Theta_{i3}^{(j)} a_3^{(j)},\n",
    "$$\n",
    "\n",
    "and in terms of $z^{(j+1)}_i$ we can define $a^{(j+1)}_i$ as:\n",
    "\n",
    "$$\n",
    "a^{(j+1)}_i = g(z^{(j+1)}_i).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can write the above in a vectorized efficient form as:\n",
    "\n",
    "\\begin{align}\n",
    "a^{(1)} = x\\\\\n",
    "z^{(2)} &= \\Theta^{(1)} \\left[\\begin{array}{c} 1 \\\\ a^{(1)} \\end{array}\\right] \\\\\n",
    "a^{(2)} &= g(z^{(2)}) \\\\\n",
    "z^{(3)} &= \\Theta^{(2)} \\left[\\begin{array}{c} 1 \\\\ a^{(2)} \\end{array}\\right] \\\\\n",
    "a^{(3)} &= g(z^{(3)}).\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "x = \\left[\\begin{array}{c} x_1 \\\\ x_2 \\\\ x_3 \\end{array}\\right], \\qquad z^{(2)} = \\left[\\begin{array}{c} z^{(2)}_1 \\\\ z^{(2)}_2 \\\\ z^{(2)}_3 \\end{array}\\right], \\qquad a^{(2)} = \\left[\\begin{array}{c} a^{(2)}_1 \\\\ a^{(2)}_2 \\\\ a^{(2)}_3 \\end{array}\\right], \\qquad z^{(3)} = z^{(3)}_1, \\qquad a^{(3)} = a^{(3)}_1,\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\Theta^{(1)} = \\left[\n",
    "\\begin{array}{cccc}\n",
    "\\Theta_{10}^{(1)} & \\Theta_{11}^{(1)} & \\Theta_{12}^{(1)} & \\Theta_{13}^{(1)}  \\\\\n",
    "\\Theta_{20}^{(1)} & \\Theta_{21}^{(1)} & \\Theta_{22}^{(1)} & \\Theta_{23}^{(1)}  \\\\\n",
    "\\Theta_{30}^{(1)} & \\Theta_{31}^{(1)} & \\Theta_{32}^{(1)} & \\Theta_{33}^{(1)} \n",
    "\\end{array}\\right],\n",
    "\\qquad \n",
    "\\Theta^{(2)} = \\left[\n",
    "\\begin{array}{cccc}\n",
    "\\Theta_{10}^{(2)} & \\Theta_{11}^{(2)} & \\Theta_{12}^{(2)} & \\Theta_{13}^{(2)} \n",
    "\\end{array}\\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is called **forward propagation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez. Based on the content of the Machine Learning course offered through coursera by Prof. Andrew Ng.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
